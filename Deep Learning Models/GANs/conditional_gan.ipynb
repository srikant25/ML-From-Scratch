{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n",
      "step-1 : generator_loss-0.970312 : discriminator_loss-1.246512\n",
      "step-2000 : generator_loss-4.930574 : discriminator_loss-0.023635\n",
      "step-4000 : generator_loss-5.139311 : discriminator_loss-0.079288\n",
      "step-6000 : generator_loss-5.334298 : discriminator_loss-0.047676\n",
      "step-8000 : generator_loss-4.383492 : discriminator_loss-0.094386\n",
      "step-10000 : generator_loss-4.551865 : discriminator_loss-0.159159\n",
      "step-12000 : generator_loss-4.837944 : discriminator_loss-0.105127\n",
      "step-14000 : generator_loss-4.964076 : discriminator_loss-0.105384\n",
      "step-16000 : generator_loss-5.579608 : discriminator_loss-0.074532\n",
      "step-18000 : generator_loss-4.238797 : discriminator_loss-0.271322\n",
      "step-20000 : generator_loss-5.229581 : discriminator_loss-0.123973\n",
      "step-22000 : generator_loss-4.318390 : discriminator_loss-0.122044\n",
      "step-24000 : generator_loss-3.847522 : discriminator_loss-0.239639\n",
      "step-26000 : generator_loss-3.703364 : discriminator_loss-0.326529\n",
      "step-28000 : generator_loss-3.962610 : discriminator_loss-0.244563\n",
      "step-30000 : generator_loss-3.129854 : discriminator_loss-0.366861\n",
      "step-32000 : generator_loss-2.968982 : discriminator_loss-0.524192\n",
      "step-34000 : generator_loss-3.039234 : discriminator_loss-0.363311\n",
      "step-36000 : generator_loss-2.892702 : discriminator_loss-0.505647\n",
      "step-38000 : generator_loss-3.059820 : discriminator_loss-0.420132\n",
      "step-40000 : generator_loss-2.862535 : discriminator_loss-0.459214\n",
      "optimization finished\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Attempted to use a closed Session.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-1284cdcedaec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[0mgenerate_plot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerate_samples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 120\u001b[1;33m \u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"trouser\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-8-1284cdcedaec>\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(inp)\u001b[0m\n\u001b[0;32m    115\u001b[0m         \u001b[0my_labels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msamples\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0my_dim\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m         \u001b[0my_labels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeature_map\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minp\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m         \u001b[0mgenerate_samples\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgen_out\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mgen_input\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mz_noise\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_input\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0my_labels\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m         \u001b[0mgenerate_plot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerate_samples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda1\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    927\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 929\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    930\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda1\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1073\u001b[0m     \u001b[1;31m# Check session.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1074\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_closed\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1075\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Attempted to use a closed Session.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1076\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mversion\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1077\u001b[0m       raise RuntimeError('The Session graph is empty.  Add operations to the '\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Attempted to use a closed Session."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "from matplotlib import gridspec\n",
    "\n",
    "\n",
    "df=input_data.read_data_sets('/tmp/data/',one_hot=True)\n",
    "\n",
    "#parameter \n",
    "img_dim=784  #28*28=784\n",
    "gen_dim=256\n",
    "dis_dim=256\n",
    "y_dim=10\n",
    "noise_dim=100\n",
    "\n",
    "gen_input=tf.placeholder(tf.float32,shape=[None,noise_dim])\n",
    "dis_input=tf.placeholder(tf.float32,shape=[None,img_dim])\n",
    "y_input=tf.placeholder(tf.float32,shape=[None,y_dim])\n",
    "\n",
    "batch_size=128\n",
    "num_step=40000\n",
    "learning_rate=2e-4\n",
    "display_step=2000\n",
    "\n",
    "def weight_init(shape):\n",
    "    return tf.random_normal(shape=shape , stddev=1./tf.sqrt(shape[0]/2.))\n",
    "\n",
    "\n",
    "#weight and bias\n",
    "W={\"w1\":tf.Variable(weight_init([noise_dim + y_dim,gen_dim])),\n",
    "   \"w2\":tf.Variable(weight_init([gen_dim,img_dim])),\n",
    "   \"w3\":tf.Variable(weight_init([img_dim +y_dim ,dis_dim])),\n",
    "   \"w4\":tf.Variable(weight_init([dis_dim,1]))}\n",
    "\n",
    "b={\"b1\":tf.Variable(tf.zeros([gen_dim])),\n",
    "   \"b2\":tf.Variable(tf.zeros([img_dim])),\n",
    "   \"b3\":tf.Variable(tf.zeros([dis_dim])),\n",
    "   \"b4\":tf.Variable(tf.zeros([1]))}\n",
    "\n",
    "\n",
    "#model architecture\n",
    "def gen_fun(x,y):\n",
    "    inputs=tf.concat(axis=1 , values=[x,y])\n",
    "    li=tf.add(tf.matmul(inputs,W[\"w1\"]),b['b1'])\n",
    "    li=tf.nn.relu(li)\n",
    "    li=tf.add(tf.matmul(li,W[\"w2\"]),b['b2'])\n",
    "    li=tf.nn.sigmoid(li)\n",
    "    return li\n",
    "\n",
    "\n",
    "def dis_fun(x,y):\n",
    "    inputs=tf.concat(axis=1 , values=[x,y])\n",
    "    l2=tf.add(tf.matmul(inputs,W[\"w3\"]),b['b3'])\n",
    "    l2=tf.nn.relu(l2)\n",
    "    l2=tf.add(tf.matmul(l2,W[\"w4\"]),b['b4'])\n",
    "    l2=tf.nn.sigmoid(l2)\n",
    "    return l2\n",
    "\n",
    "#cost function optimization and model evaluation\n",
    "\n",
    "gen_out=gen_fun(gen_input,y_input)\n",
    "dis_real_out=dis_fun(dis_input,y_input)\n",
    "dis_fake_out=dis_fun(gen_out,y_input)\n",
    "\n",
    "cost_gen=-tf.reduce_mean(tf.log(dis_fake_out + .00001))\n",
    "cost_dis=-tf.reduce_mean(tf.log(dis_real_out + .00001) + tf.log(1. - dis_fake_out + .00001))\n",
    "\n",
    "var_gen =[W['w1'],W['w2'],b['b1'],b['b2']]\n",
    "var_dis=[W['w3'],W['w4'],b['b3'],b['b4']]\n",
    "\n",
    "training_gen=tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost_gen,var_list=var_gen)\n",
    "\n",
    "training_dis=tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost_dis,var_list=var_dis)\n",
    "\n",
    "#initialize the variable\n",
    "init=tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for step in range(1,num_step+1):\n",
    "        \n",
    "        batch_x,y_label=df.train.next_batch(batch_size)\n",
    "        \n",
    "        #generate the noise sample\n",
    "        \n",
    "        noise_temp=np.random.uniform(-1.,1.,size=[batch_size,noise_dim])\n",
    "        \n",
    "        feed_dict={dis_input:batch_x,y_input : y_label,gen_input:noise_temp}\n",
    "        \n",
    "        _,_,gl,dl=sess.run([training_gen,training_dis,cost_gen,cost_dis],feed_dict=feed_dict)\n",
    "        \n",
    "        if step % display_step==0 or step==1 :\n",
    "            \n",
    "            print('step-%i : generator_loss-%f : discriminator_loss-%f' % (step , gl,dl))\n",
    "            \n",
    "    print('optimization finished')\n",
    "\n",
    "def generate_plot(samples):\n",
    "    fig = plt.figure(figsize=(4,4))\n",
    "    gs=gridspec.GridSpec(4,4)\n",
    "    gs.update(wspace=.05 , hspace=.05)\n",
    "    for i,sample in enumerate(samples):\n",
    "        ax=plt.subplot(gs[i])\n",
    "        plt.axis('off')\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        #ax.set_aspects('equal')\n",
    "        plt.imshow(sample.reshape(28,28), cmap='gray')\n",
    "    return fig\n",
    "\n",
    "\n",
    "def create(inp):\n",
    "        feature_map={\"t-shirt\":0 , \"trouser\":1 , \"pullover\":2 , \"dress\":3 , \"coat\":4 , \"sandal\":5 , \"shirt\":6 , \"sneaker\":7 , \"bag\":8 , \"ankel boot\":9}\n",
    "        samples=16\n",
    "        z_noise=np.random.uniform(-1.,1.,size=[samples,noise_dim])\n",
    "        y_labels=np.zeros(shape=[samples , y_dim])\n",
    "        y_labels[:,feature_map[inp]]=1\n",
    "        generate_samples =sess.run(gen_out , feed_dict={gen_input:z_noise,y_input:y_labels})\n",
    "        generate_plot(generate_samples)\n",
    "\n",
    "create(\"trouser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
